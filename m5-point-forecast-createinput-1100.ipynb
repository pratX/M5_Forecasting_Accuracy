{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/m5-forecasting-calendar-events-minfeats/events.pkl\n",
      "/kaggle/input/m5-forecasting-calendar-events-minfeats/custom.css\n",
      "/kaggle/input/m5-forecasting-calendar-events-minfeats/__notebook__.ipynb\n",
      "/kaggle/input/m5-forecasting-calendar-events-minfeats/__results__.html\n",
      "/kaggle/input/m5-forecasting-calendar-events-minfeats/__output__.json\n",
      "/kaggle/input/m5-forecasting-calendar-events-minfeats/calendar_events.csv\n",
      "/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\n",
      "/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv\n",
      "/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\n",
      "/kaggle/input/m5-forecasting-accuracy/calendar.csv\n",
      "/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import gc\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class Category:\n",
    "    def __init__(self, unique_items, item_to_id={}):\n",
    "        self.items = unique_items\n",
    "        self.item_to_id = item_to_id\n",
    "        for _id, item_name in enumerate(self.items):\n",
    "            self.item_to_id[item_name] = _id\n",
    "        self.type = np.int16\n",
    "        if len(self.items) > 30000:\n",
    "            self.type = np.int32\n",
    "    \n",
    "    def encode_series(self, items):\n",
    "        return np.array([self.item_to_id[_item] for _item in items]).astype(self.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_val = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_eval = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd_1',\n",
       "       'd_2', 'd_3', 'd_4',\n",
       "       ...\n",
       "       'd_1904', 'd_1905', 'd_1906', 'd_1907', 'd_1908', 'd_1909', 'd_1910',\n",
       "       'd_1911', 'd_1912', 'd_1913'],\n",
       "      dtype='object', length=1919)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats_name2idx = {ft:i for i, ft in enumerate(cat_feats)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats_objs = []\n",
    "for col in cat_feats:\n",
    "    cat_feats_objs.append(Category(sorted(sales_train_eval[col].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices = pd.read_csv('../input/m5-forecasting-accuracy/sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices.set_index(['item_id', 'store_id', 'wm_yr_wk'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv('../input/m5-forecasting-calendar-events-minfeats/calendar_events.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = calendar.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.set_index('d', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>...</th>\n",
       "      <th>LentStart_lag</th>\n",
       "      <th>Thanksgiving_lag</th>\n",
       "      <th>Purim End_lag</th>\n",
       "      <th>VeteransDay_lag</th>\n",
       "      <th>Ramadan starts_lag</th>\n",
       "      <th>Mother's day_lag</th>\n",
       "      <th>NBAFinalsStart_lag</th>\n",
       "      <th>Easter_lag</th>\n",
       "      <th>NBAFinalsEnd_lag</th>\n",
       "      <th>LaborDay_lag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d_1</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_2</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_3</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_4</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_5</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_1965</th>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>11620</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>202</td>\n",
       "      <td>83</td>\n",
       "      <td>217</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>365</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_1966</th>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>11620</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>203</td>\n",
       "      <td>84</td>\n",
       "      <td>218</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>81</td>\n",
       "      <td>366</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_1967</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>11620</td>\n",
       "      <td>Friday</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>204</td>\n",
       "      <td>85</td>\n",
       "      <td>219</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>82</td>\n",
       "      <td>367</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_1968</th>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>11621</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>129</td>\n",
       "      <td>205</td>\n",
       "      <td>86</td>\n",
       "      <td>220</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "      <td>368</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_1969</th>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>NBAFinalsEnd</td>\n",
       "      <td>Sporting</td>\n",
       "      <td>Father's day</td>\n",
       "      <td>Cultural</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>206</td>\n",
       "      <td>87</td>\n",
       "      <td>221</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1969 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  wm_yr_wk    weekday  wday  month  year  event_name_1  \\\n",
       "d                                                                         \n",
       "d_1    2011-01-29     11101   Saturday     1      1  2011           NaN   \n",
       "d_2    2011-01-30     11101     Sunday     2      1  2011           NaN   \n",
       "d_3    2011-01-31     11101     Monday     3      1  2011           NaN   \n",
       "d_4    2011-02-01     11101    Tuesday     4      2  2011           NaN   \n",
       "d_5    2011-02-02     11101  Wednesday     5      2  2011           NaN   \n",
       "...           ...       ...        ...   ...    ...   ...           ...   \n",
       "d_1965 2016-06-15     11620  Wednesday     5      6  2016           NaN   \n",
       "d_1966 2016-06-16     11620   Thursday     6      6  2016           NaN   \n",
       "d_1967 2016-06-17     11620     Friday     7      6  2016           NaN   \n",
       "d_1968 2016-06-18     11621   Saturday     1      6  2016           NaN   \n",
       "d_1969 2016-06-19     11621     Sunday     2      6  2016  NBAFinalsEnd   \n",
       "\n",
       "       event_type_1  event_name_2 event_type_2  ...  LentStart_lag  \\\n",
       "d                                               ...                  \n",
       "d_1             NaN           NaN          NaN  ...             -1   \n",
       "d_2             NaN           NaN          NaN  ...             -1   \n",
       "d_3             NaN           NaN          NaN  ...             -1   \n",
       "d_4             NaN           NaN          NaN  ...             -1   \n",
       "d_5             NaN           NaN          NaN  ...             -1   \n",
       "...             ...           ...          ...  ...            ...   \n",
       "d_1965          NaN           NaN          NaN  ...            126   \n",
       "d_1966          NaN           NaN          NaN  ...            127   \n",
       "d_1967          NaN           NaN          NaN  ...            128   \n",
       "d_1968          NaN           NaN          NaN  ...            129   \n",
       "d_1969     Sporting  Father's day     Cultural  ...            130   \n",
       "\n",
       "        Thanksgiving_lag  Purim End_lag  VeteransDay_lag  Ramadan starts_lag  \\\n",
       "d                                                                              \n",
       "d_1                   -1             -1               -1                  -1   \n",
       "d_2                   -1             -1               -1                  -1   \n",
       "d_3                   -1             -1               -1                  -1   \n",
       "d_4                   -1             -1               -1                  -1   \n",
       "d_5                   -1             -1               -1                  -1   \n",
       "...                  ...            ...              ...                 ...   \n",
       "d_1965               202             83              217                   8   \n",
       "d_1966               203             84              218                   9   \n",
       "d_1967               204             85              219                  10   \n",
       "d_1968               205             86              220                  11   \n",
       "d_1969               206             87              221                  12   \n",
       "\n",
       "        Mother's day_lag  NBAFinalsStart_lag  Easter_lag  NBAFinalsEnd_lag  \\\n",
       "d                                                                            \n",
       "d_1                   -1                  -1          -1                -1   \n",
       "d_2                   -1                  -1          -1                -1   \n",
       "d_3                   -1                  -1          -1                -1   \n",
       "d_4                   -1                  -1          -1                -1   \n",
       "d_5                   -1                  -1          -1                -1   \n",
       "...                  ...                 ...         ...               ...   \n",
       "d_1965                38                  13          80               365   \n",
       "d_1966                39                  14          81               366   \n",
       "d_1967                40                  15          82               367   \n",
       "d_1968                41                  16          83               368   \n",
       "d_1969                42                  17          84                 0   \n",
       "\n",
       "        LaborDay_lag  \n",
       "d                     \n",
       "d_1               -1  \n",
       "d_2               -1  \n",
       "d_3               -1  \n",
       "d_4               -1  \n",
       "d_5               -1  \n",
       "...              ...  \n",
       "d_1965           282  \n",
       "d_1966           283  \n",
       "d_1967           284  \n",
       "d_1968           285  \n",
       "d_1969           286  \n",
       "\n",
       "[1969 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'day_id',\n",
    "       'week_id', 'year', 'month', 'day_of_month', 'day_of_week', 'snap',\n",
    "       'sell_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/m5-forecasting-calendar-events-minfeats/events.pkl', 'rb') as f:\n",
    "    events = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_feats = []\n",
    "for event in events:\n",
    "    event_feats.append(event+\"_lag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ef in event_feats:\n",
    "    calendar[ef] = calendar[ef].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = col_names + event_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id',\n",
       " 'dept_id',\n",
       " 'cat_id',\n",
       " 'store_id',\n",
       " 'state_id',\n",
       " 'day_id',\n",
       " 'week_id',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day_of_month',\n",
       " 'day_of_week',\n",
       " 'snap',\n",
       " 'sell_price',\n",
       " 'Chanukah End_lag',\n",
       " 'SuperBowl_lag',\n",
       " 'StPatricksDay_lag',\n",
       " 'LaborDay_lag',\n",
       " 'Pesach End_lag',\n",
       " 'PresidentsDay_lag',\n",
       " 'NewYear_lag',\n",
       " 'ColumbusDay_lag',\n",
       " 'Ramadan starts_lag',\n",
       " 'Purim End_lag',\n",
       " 'LentWeek2_lag',\n",
       " 'Thanksgiving_lag',\n",
       " 'IndependenceDay_lag',\n",
       " 'Christmas_lag',\n",
       " 'NBAFinalsStart_lag',\n",
       " \"Father's day_lag\",\n",
       " 'LentStart_lag',\n",
       " 'EidAlAdha_lag',\n",
       " 'VeteransDay_lag',\n",
       " 'MartinLutherKingDay_lag',\n",
       " 'Cinco De Mayo_lag',\n",
       " 'Halloween_lag',\n",
       " 'Easter_lag',\n",
       " 'NBAFinalsEnd_lag',\n",
       " 'OrthodoxChristmas_lag',\n",
       " 'ValentinesDay_lag',\n",
       " 'MemorialDay_lag',\n",
       " 'Eid al-Fitr_lag',\n",
       " 'OrthodoxEaster_lag',\n",
       " \"Mother's day_lag\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(progress_str, n_cols=80):\n",
    "    sys.stdout.write(progress_str + (\" \" * max(0, n_cols - len(progress_str))) + \"\\r\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_start=1900\n",
    "#d_end=1906\n",
    "\n",
    "def build_lgbm_input_df(sales_df, d_start, d_end, col_names=col_names):\n",
    "    item_store_df = pd.DataFrame({ cat_feats[i]:cat_feats_objs[i].encode_series(sales_df[cat_feats[i]]) for i in range(len(cat_feats)) })\n",
    "    all_cols = defaultdict(list)\n",
    "    sales = []\n",
    "    for d in range(d_start, d_end+1):\n",
    "        show_progress(f\"Processing day {d} of {d_end}\")\n",
    "        sales.append(sales_df['d_'+str(d)].values)\n",
    "        for feat in cat_feats:\n",
    "            all_cols[feat].append(item_store_df[feat].values)\n",
    "        all_cols['day_id'].append(np.array([d] * len(item_store_df)).astype(np.int16))\n",
    "        wk_id = calendar.loc['d_'+str(d), 'wm_yr_wk']\n",
    "        all_cols['week_id'].append(np.array([wk_id] * len(item_store_df)).astype(np.int16))\n",
    "        year = calendar.loc['d_'+str(d),'year']\n",
    "        all_cols['year'].append(np.array([year] * len(item_store_df)).astype(np.int16))\n",
    "        month = calendar.loc['d_'+str(d),'month']\n",
    "        all_cols['month'].append(np.array([month] * len(item_store_df)).astype(np.int8))\n",
    "        day_of_month = calendar.loc['d_'+str(d),'date'].day\n",
    "        all_cols['day_of_month'].append(np.array([day_of_month] * len(item_store_df)).astype(np.int8))\n",
    "        day_of_week = calendar.loc['d_'+str(d), 'wday']\n",
    "        all_cols['day_of_week'].append(np.array([day_of_week] * len(item_store_df)).astype(np.int8))\n",
    "        state = [cat_feats_objs[cat_feats_name2idx['state_id']].items[s_id] for s_id in item_store_df.state_id]\n",
    "        all_cols['snap'].append(np.array([calendar.loc['d_'+str(d), 'snap_'+state[i]] for i in range(len(item_store_df))]).astype(np.int8))\n",
    "        sp = []\n",
    "        for i in range(len(item_store_df)):\n",
    "            try:\n",
    "                _item = cat_feats_objs[cat_feats_name2idx['item_id']].items[item_store_df.iloc[i,0]]\n",
    "                _store = cat_feats_objs[cat_feats_name2idx['store_id']].items[item_store_df.iloc[i,3]]\n",
    "                _sp = sell_prices.loc[(_item,_store,wk_id)].values[0]\n",
    "            except:\n",
    "                _sp = -1\n",
    "            sp.append(_sp)\n",
    "        all_cols['sell_price'].append(np.array(sp).astype(np.float32))\n",
    "        for ef in event_feats:\n",
    "            all_cols[ef].append(np.array([calendar.loc['d_'+str(d), ef]] * len(item_store_df)))\n",
    "\n",
    "    print(\"\")\n",
    "    all_cols_temp = {}\n",
    "    for k,v in all_cols.items():\n",
    "        all_cols_temp[k] = np.concatenate(v)\n",
    "    all_cols = all_cols_temp\n",
    "    del all_cols_temp\n",
    "    gc.collect()\n",
    "    return pd.DataFrame(all_cols)[col_names], np.concatenate(sales).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing day 1913 of 1913                                                     \r\n",
      "CPU times: user 1h 57min 7s, sys: 9.02 s, total: 1h 57min 16s\n",
      "Wall time: 1h 57min 17s\n"
     ]
    }
   ],
   "source": [
    "# train_train_split\n",
    "# upto -28 days\n",
    "# ~90 days\n",
    "# d_end: 1885\n",
    "# d_start: 1795\n",
    "%time X_train_df, y_train = build_lgbm_input_df(sales_train_eval, 1100, 1913)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.to_pickle('X_train_df')\n",
    "np.save('y_train', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing day 1941 of 1941                                                     \r\n"
     ]
    }
   ],
   "source": [
    "X_val_df, y_val = build_lgbm_input_df(sales_train_eval, 1914, 1941)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_df.to_pickle('X_val_df')\n",
    "np.save('y_val', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full_df = pd.concat((X_train_df, X_val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full_df.to_pickle('X_train_full_df')\n",
    "np.save('y_train_full', y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat_feats.pkl', 'wb') as f:\n",
    "    pickle.dump(cat_feats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat_feats_name2idx.pkl', 'wb') as f:\n",
    "    pickle.dump(cat_feats_name2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat_feats_objs.pkl', 'wb') as f:\n",
    "    pickle.dump(cat_feats_objs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.4G\r\n",
      "-rw-r--r-- 1 root root 3.3M Jun 25 20:22 y_val.npy\r\n",
      "-rw-r--r-- 1 root root  98M Jun 25 20:22 y_train_full.npy\r\n",
      "-rw-r--r-- 1 root root  95M Jun 25 20:18 y_train.npy\r\n",
      "-rw-r--r-- 1 root root  91K Jun 25 20:22 cat_feats_objs.pkl\r\n",
      "-rw-r--r-- 1 root root   89 Jun 25 20:22 cat_feats_name2idx.pkl\r\n",
      "-rw-r--r-- 1 root root   79 Jun 25 20:22 cat_feats.pkl\r\n",
      "---------- 1 root root  11K Jun 25 18:20 __notebook__.ipynb\r\n",
      "-rw-r--r-- 1 root root  69M Jun 25 20:22 X_val_df\r\n",
      "-rw-r--r-- 1 root root 2.2G Jun 25 20:22 X_train_full_df\r\n",
      "-rw-r--r-- 1 root root 2.0G Jun 25 20:18 X_train_df\r\n",
      "drwxr-xr-x 6 root root 4.0K Jun 25 18:20 ..\r\n",
      "drwxr-xr-x 2 root root 4.0K Jun 25 20:22 .\r\n"
     ]
    }
   ],
   "source": [
    "! ls -alrh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
